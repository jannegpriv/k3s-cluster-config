apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: k3s-alert-rules
  namespace: monitoring
  labels:
    release: kube-prometheus-stack
    prometheus: kube-prometheus-stack-prometheus
spec:
  groups:
    - name: K3sAlerts
      rules:
        # Disable false positives for k3s components that are embedded
        - alert: KubeControllerManagerDown
          expr: absent(up{job="kube-controller-manager"} == 1)
          for: 5m
          labels:
            severity: none
            silent: "true"  # This will prevent email notifications
          annotations:
            description: "This alert is disabled for k3s as the controller manager is embedded"
            summary: "Expected state - KubeControllerManager is embedded in k3s"

        - alert: KubeSchedulerDown
          expr: absent(up{job="kube-scheduler"} == 1)
          for: 5m
          labels:
            severity: none
            silent: "true"  # This will prevent email notifications
          annotations:
            description: "This alert is disabled for k3s as the scheduler is embedded"
            summary: "Expected state - KubeScheduler is embedded in k3s"

        - alert: KubeProxyDown
          expr: absent(up{job="kube-proxy"} == 1)
          for: 5m
          labels:
            severity: none
            silent: "true"  # This will prevent email notifications
          annotations:
            description: "This alert is disabled for k3s as kube-proxy is managed differently"
            summary: "Expected state - KubeProxy is embedded in k3s"

        # Add k3s-specific monitoring
        - alert: K3sServiceDown
          expr: up{job="k3s"} == 0 or absent(up{job="k3s"} == 1)
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "K3s service is down"
            description: "K3s service has been down for more than 5 minutes."

        # Adjusted latency thresholds for k3s on ARM
        - alert: ApiServerHighLatency
          expr: histogram_quantile(0.99, sum by(le, verb) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|WATCH"}[5m]))) > 2
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: "API server high latency"
            description: "99th percentile of request latency is above 2 seconds for {{ $labels.verb }} requests. This may indicate k3s CPU pressure."

        - alert: ApiServerCriticalLatency
          expr: histogram_quantile(0.99, sum by(le, verb) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|WATCH"}[5m]))) > 10
          for: 15m
          labels:
            severity: critical
          annotations:
            summary: "API server critical latency"
            description: "99th percentile of request latency is above 10 seconds for {{ $labels.verb }} requests. Consider restarting k3s.service."

        - alert: K3sHighCPU
          expr: rate(process_cpu_seconds_total{job="k3s"}[5m]) * 100 > 80
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: "K3s high CPU usage"
            description: "K3s is using more than 80% CPU for over 15 minutes."
